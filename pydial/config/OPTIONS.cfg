#This file is not a config file, it only gives the options avaliable to a config file. default values are written (or written first) 
#where possible.
#Config files are read into the Settings.config global, which is an instance of the python standard library module ConfigParser.
#One general note: there is no heirachy available in the python ConfigParser module - so format is to add domain identifier tags
#    to specify domain dependent properties. For example semi options in CamRestaurants are found under [semi_CamRestaurants]
#    Option sections without a domain tag are thus domain independent. 
# 
#(note - default options are hardcoded into the appropriate .py file, and are overridden by the config file provided choice when given)


###### General parameters ######

[GENERAL]      
domains = CamRestaurants,CamHotels,CamAttractions,CamTransport,CamShops,SFHotels,SFRestaurants,Laptops11,Laptops6,TSBplayer,TSBextHD,TV
            # One or selection of these tags, which cover all domains we currently have. (no spaces inbetween domains or commas)
            # Can alternatively specify names of groups: 'camtourist','sftourist','electronics','all'
            # Note that the list of domains (or single domain) given only provides a restriction on the simulated user; interacting
            # via DialogueServer you can say anything at any turn to move to any one of the available domains (provided topic tracker
            # can get you there!). 
            
root = /path/to/repository/cued-pydial/     # when running on the grid, or generating tasks - allows repo path to be found
singledomain = False    # setting this means that no topic tracking is used and system works just like a single domain system. 
                        #Must only give 1 domain tag under domains if so.
seed = 100   # Will seed the random number generator - note that is overriden by any seed given as cmd line argument
             # Using the same seed for simulate runs etc will result in exactly the same dialogues (and therefore results)
             # as all random number generation within the repository comes from Settings.random which is an numpy.random.RandomState
             # object seeded with seed. If seed is not give - essentially the system clock is used as a seed.  
tracedialog = 0     # set trace level to 0,1 or 2 regulating what is printed out to teminal (not trtough logger)

[exec_config] # There parameters are used by the pydial.py wrapper
domain = CamRestaurants # the name of the domain or "Multi" if there are several domains
configdir = _configs # path where the temporary config files 
logfiledir = _logs # path where the logs will be saved (this overrides [logging] file)
numtrainbatches = 20 # number of training batches
traindialogsperbatch = 300 # number of training dialogues per batch
numbatchtestdialogs =  1800 # number of testing dialogues per batch
trainsourceiteration = 0 # first training iteration (if set to zero it trains from scratch, else will find the corresponding file trained
			 # in a previous run)
numtestdialogs =  0 # number of test dialogues performed after the last iteration (batch) has been completed
trainerrorrate = 15 # simulated semantic error rate during training (also for the testing after each batch)
testerrorrate  = 15 # simulated semantic error rate during testing (only for the pydial.py "test" option)
testeverybatch = True # if every training batch should be tested
deleteprevpolicy = True # if the policy files should be deleted after each batch

[agent]
savefrequency = 10  # If doing policy learning, all policies are saved modulo this number of dialogs
maxturns = 20   # Note that for multidomain tasks in simulate - this is the maximum number of turn PER DOMAIN OCCURING IN THE DIALOG
                # so for example, one dialogue may involve 3 domains - so max turns for this dialogue will be 3*maxturns etc. 
systemcanhangup = False     # can the system issue the bye() act?  
mindialoguedurationprompt = "Please go on." # prompt issued if user says good-bye too early
mindialogueturns = 0 # Min number of turns before user is allowed to say good-bye.
mindialogueduration = 0 # min seconds to pass before user is allowed to say good-bye.
policymanager = policy.PolicyManager.PolicyManager
evaluationmanager = evaluation.EvaluationManager.EvaluationManager
semanticbelieftrackingmanager = semanticbelieftracking.SemanticBeliefTrackingManager.SemanticBeliefTrackingManager
semomanager = semo.SemOManager.SemOManager


[dialogueserver]
dialhost = nui.eng.cam.ac.uk  or localhost              # host name HTML connections made to ...
dialport = 8082                                         # ... at this port.
tasksfile = tasks/tasks1000.json        # output file from Tasks.TasksCreator() run.
generatetoken = True            # create, post to camdial at end of dialogue, and CamRestaurantsS a 4 digit token for camdial landing page.
tokenserverurl = "http://www.camdial.org/~djv27/mt-multiDomain/receive-token.py"    # if generatetoken --> then post 4 digits to here
subjectivefeedback = True       # collect at dialogue completion, via DTMF, users 0 or 1 feedback on success of dialogue.
subjectivefeedbackprompt = Was the dialogue successful? Press 1 for yes, 0 for no. # the text to be prompted to the user to collect subjective feedback
collecttask = True      # collect from the user the 5 digit task id (from the camdial landing page) --> should correspond to 
                        # one of the tasks within tasksfile.

[logging]
screen_level = info # or results or dial or  warning or debug or error or critical (see https://docs.python.org/2/library/logging.html#levels)
file_level = info # or results or dial or  warning or debug or error or critical
file =  #path and filename to log to.
file_append = False # can toggle whether a new log file is created for each run or logging is appended to existing file
usecolor = True     # can toggle color on/off for logging - since when dumping to file the color encoders dont print well, 
                    # so best to turn this off.
UMHdcSim = debug  # example of individual module control of logging level -- TODO currently has problems. 

###### Environment parameters ######

[simulate]
forcenullpositive = False    # must the act 'null()' be present in the semantic input parse hypotheses with some non zero prob? 
includedomainprob = 0.6     # when forming tasks, a first domain is chosen randomly from the given domains - and then 
                            # based on the min and max domains per dialog settings - and hardcoded rules in OntologyUtils.py regarding
                            # what domains can co-occur in tasks - domains are added to this first domain stochastically.  
mindomainsperdialog = 3     # min ... 
maxdomainsperdialog = 3     # ... and max allowed domains in each dialogue. topicmanager doesn't count.
generateprompots = False    # controls whether readable prompts are generated from the system act and printed to screen 
domainsampling = random or roundrobin # to set the number of dialogues in each domain random or the same

[conditional]
conditionalsimuser = False       # for the simulated user in multi-domain case - generated behaviour in next domain (2,3,4 etc)
                                # that depends on what occured in domains prior (1, etc)
conditionalbeliefs = False       # for all hubs in multi-domain scenario - initiate the belief state
                                # using constraints determined in other domains. based on rules to do this. 
[usermodel]
patience = 10           # simulated user will end dialogue after this many repeats of same semantic act from policy
usenewgoalscenarios = False     # generate new goals if we reach a certain failure point - understood but no entity met
answerreqalways = False     # if requested slot is not on the agenda - do we have to answer the request ?
informcombinationprob = 0.6  # probability of combining more inform etc acts on the agenda stack to one user act
affirmcombinationprob = 1.0  # probability of adding information (like in an inform act) an affirm user act
oldstylepatience = False    # old style patience, level restored if different action is issued
sampledialogueprobs = False # sample user model probabilities and patience in [2,10]
configfile = usersimulator/defaultUM.cfg # path to config file with UM parameters

[errormodel]
nbestsize = 5     # how many semantic hypotheses to simulate? 
confusionmodel = RandomConfusions       # or LevenshteinConfusions
confscorer = additive or DSTC2      # confidence scoring mechanism in simulated semantic hypotheses.
nbestgeneratormodel = UniformNBestGenerator or SampledNBestGenerator or DSTC2NBestGenerator       # or an available method
configfile = usersimulator/defaultUM.cfg # path to config file with EM parameters

[goalgenerator]
maxvenuespergoal = 3    # find set of constraints that limits number of possible entities to this or less. 
maxconstraints = 3      # max num slot constraints
maxrequests = 3         # and max num slot requests    - eg name, phone and address
minrequests = 1         #  min num slot requests - ie just name
#MINVENUESPERGOAL = 3        # unused
#PERCZEROSOLUTION = 2        # unused
#NOREQUESTSWITHVALUENONE = 2    # unused

[tasks]
numtasks = 1000                 # number of tasks to create
savename = tasks/tasks1000      # path and name for tasks to be written. No extension needed as 2 files will be created, one for 
                                # DialogueServer (loaded via tasksfile config option) and one for camdial landing page.
savedir = tasks                 # directory the task file should be saved if 


[topictracker]
type = keyword or switch    # or any kind of available topic tracker

[policy]
maxinformslots = 5 # Maximum number of slot values that are presented in the inform summary action
informmask = True # Decides if the mask over inform type actions is used or not (having the mask active speeds up learning)
informcountaccepted = 4 # number of accepted slots needed to unmask the inform_byconstraints action
requestmask = True # Decides if the mask over inform type actions is used or not
byemask = True # Decides if the mask over the bye action is used or not

[policy_topicmanager]
maxattempts = 3      # number of attempts the system tries to figure out the domain of the conversation in the beginning

###### Dialogue Manager parameters ######

[policycommittee]            
bcm = False             # use BCM or not?        # Note that you need to set abstractslots to True under [gppolicy_XX]
pctype = hdc  or configset      # configset option requires configsetcommittee below
configsetcommittee = list of domains to be in committee if using above configset
learningmethod = singleagent or multiagent      # ** GP policies will only learn if their  [policy_CamRestaurants] learning option is True. **
                                                # Default is just to do single agent learning - whereby only domain where
                                                # actions are actually being taken is learning - with multiagent learning
                                                # all in committee will learn (noting above proviso)
                                                # Note that multiagent distributes rewards according to the NAIVE approach from
                                                # Milica's NIPS workshop paper

[policy_CamRestaurants]  # These are available for all domain strings, not just CamRestaurants
belieftype = focus or baseline  # or any kind of available tracker 
useconfreq = False      # use confirm request ?
learning = False         # policy learning?
outpolicyfile = path to pol file for saving     # for GP (or can be for any other learnt policy)    
inpolicyfile = path for loading             # in policy file for GP
policytype = hdc or gp            # or any other choice of available policy
startwithhello = False      # domain dependent setting - note that this is overruled and set to True if using single domain 
                            # option - such that first turn is always ignored for evaluation because it is either the topic manager
                            # or it is a in domain policy (in singledomain=True case) just saying hello()
preload = False           # boots up domain policy already at startup (and not when first accessed)


[gppolicy_CamRestaurants]  # relevant only if policytype under policy_CamRestaurants is set to gp
kernel = polysort   or gausssort  # or choice of any avaiable BELIEF kernel method
actionkerneltype = delta or hdc or distributed # or any other available action kernel method
abstractslots = False       # if using BCM then set this to true - otherwise false
unabstractslots = False     # if BCM was used in training policy - and not using BCM now - then need to unabstract
thetafile = ''              # belief kernel hyperparameters file
slotabstractionfile = ''    # default is to use hardcoded mapping found in policy/slot_abstraction/ but can given another one here
                            # for BCM - abstract domain specific action to which abstract action?
distlength = 20             # for distributed action kernel


[gpsarsa_CamRestaurants]
random = False      # behave randomly or not
scale = 3           # sample from Gaussians of mean and std dev * scale -- basically in learning set > 1 (encouraging exploration)
                    # and for testing set = 1.  Can set this to -1 just to take the mean (ie no sampling)
saveasprior = False     # save policy as a prior
saveasnpy = False    # store parameters in numpy format which takes much less space
numprior = 0        # number of prior means        - zero mean is assumed otherwise.
gamma = 1.0         # discount factor (our episodes will always end - so 1.0 is standard)
sigma = 5.0     # 
nu = 0.001      # dictionary sparcification threshold 

[feudalpolicy]
features = dip # dip or learned or rnn
sortbelief = True # beleif is sorted (used in learned or rnn)
si_enc_size = 25 # size of the slot belief ecoding size (used in learned or rnn)
dropout_rate = 0 # dropout rate (used in learned or rnn)
si_policy_type = dqn # type of the slot independent policy (dqn or acer or enac or bbqn)
sd_policy_type = dqn # type of the slot dependent policy (dqn or bbqn)
master_policy_type = dqn # type of the master policy (dqn or acer or enac or bbqn)
actfreq_ds = True # should the action frequencies be included in the policy input


[policy_ood]
maxood = 2      # the number of ood input before the dialogue is terminated; usually not used

[semi_CamRestaurants]
semitype = PassthroughSemI or  RegexSemI or SVMSemI   # or any other available semi method

[semibelief_CamRestaurants]
type = modularSemiBelief      # the semibelief type if used, defaults to modular behaviour

[semo_CamRestaurants]
semotype = PassthroughSemO or BasicSemO or RNNSemO # or any other available NLG method - sclstm!!! - (BasicSemO requires a templatefile) 
templatefile = semo/templates/CamRestaurantsMessages.txt      # template file for BasicSemO class
emphasis = False  # generate emphasis tags or not 
emphasisopen = '<EMPH>' 
emphasisclose = '</EMPH>'
configfile = ...      # config file of RNNSemO

###### Evaluation parameters ######

[eval]
rewardvenuerecommended=0          # was an entity matching constraints offered? if so on that turn policy recieved this reward
penaliseallturns = True             # use -1 per turn?
wrongvenuepenalty = 0               # reward for opposite case of rewardvenuerecommended (should be positive value if used)
notmentionedvaluepenalty = 0        # select or confirm action taken on unmentioned slot --> incurr this penalty (is subtracted, so
                                    # if using, this value should be positive)

[eval_CamRestaurants]        # domain dependent evaluation options
successmeasure = subhective or objective       # or other available measure
successreward = 20      # domain dependent reward for overall dialogue success
failpenalty = 0        # domain dependent penalty for overall failing dialouge; final reward = success ? successreward : -failpenalty
multievaluatorlist = evaluation.SuccessEvaluator.ObjectiveSuccessEvaluator, evaluation.SuccessEvaluator.SubjectiveSuccessEvaluator # only multievaluator: list of evaluators to be used for the mutlievaluator
mainevaluator = 0 # only multievaluator: the index of the main evaluator which is used for training
compareevaluator = None # only multievaluator: comparison evaluator to definine dialogues which may be used for training
